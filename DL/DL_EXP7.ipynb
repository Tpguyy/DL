{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nikhi\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import layers, models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('/content/student_data.csv')\n","data = pd.get_dummies(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_features = len(data.columns)\n","latent_dim = 100  # Example dimension of latent space\n","num_epochs = 100\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_generator(latent_dim):\n","    model = models.Sequential()\n","    model.add(layers.Dense(64, activation='relu', input_dim=latent_dim))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(256, activation='relu'))\n","    model.add(layers.Dense(num_features, activation='sigmoid'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_discriminator(num_features):\n","    model = models.Sequential()\n","    model.add(layers.Dense(256, activation='relu', input_dim=num_features))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["discriminator = build_discriminator(num_features)\n","discriminator.compile(loss='binary_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator = build_generator(latent_dim)\n","gan_input = tf.keras.Input(shape=(latent_dim,))\n","fake_student = generator(gan_input)\n","gan_output = discriminator(fake_student)\n","gan = tf.keras.models.Model(gan_input, gan_output)\n","discriminator.trainable = False\n","gan.compile(loss='binary_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = data.values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15213,"status":"ok","timestamp":1710387323553,"user":{"displayName":"HM HM","userId":"02074890902011325871"},"user_tz":-330},"id":"ITdr9sGW9rOV","outputId":"00a39284-6fab-4020-819c-aa1336e7c2b2"},"outputs":[],"source":["discriminator_losses = []\n","for epoch in range(num_epochs):\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    fake_student_data = generator.predict(noise)\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    real_student_data = X_train[idx]\n","    d_loss_real = discriminator.train_on_batch(real_student_data, np.ones((batch_size, 1)))\n","    d_loss_fake = discriminator.train_on_batch(fake_student_data, np.zeros((batch_size, 1)))\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","    discriminator_losses.append(d_loss)\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n","    print(f\"Epoch: {epoch+1}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n","\n","threshold = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake_students = []\n","real_students = []\n","\n","for epoch, discriminator_loss in enumerate(discriminator_losses, 1):\n","    if discriminator_loss < threshold:\n","        fake_students.append((epoch, discriminator_loss))\n","    else:\n","        real_students.append((epoch, discriminator_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Fake Students:\")\n","for student in fake_students:\n","    print(\"Epoch:\", student[0], \"Discriminator Loss:\", student[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nReal Students:\")\n","for student in real_students:\n","    print(\"Epoch:\", student[0], \"Discriminator Loss:\", student[1])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPuJ4CK18AERwP1I9kWfiAU","gpuType":"T4","mount_file_id":"129v2e_s_XoyMsBD3wM3WJhD_nDt8H4VW","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
