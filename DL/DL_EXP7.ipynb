{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import layers, models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('/content/student_data.csv')\n","data = pd.get_dummies(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_features = len(data.columns)\n","latent_dim = 100  # Example dimension of latent space\n","num_epochs = 100\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_generator(latent_dim):\n","    model = models.Sequential()\n","    model.add(layers.Dense(64, activation='relu', input_dim=latent_dim))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(256, activation='relu'))\n","    model.add(layers.Dense(num_features, activation='sigmoid'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_discriminator(num_features):\n","    model = models.Sequential()\n","    model.add(layers.Dense(256, activation='relu', input_dim=num_features))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["discriminator = build_discriminator(num_features)\n","discriminator.compile(loss='binary_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator = build_generator(latent_dim)\n","gan_input = tf.keras.Input(shape=(latent_dim,))\n","fake_student = generator(gan_input)\n","gan_output = discriminator(fake_student)\n","gan = tf.keras.models.Model(gan_input, gan_output)\n","discriminator.trainable = False\n","gan.compile(loss='binary_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = data.values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15213,"status":"ok","timestamp":1710387323553,"user":{"displayName":"HM HM","userId":"02074890902011325871"},"user_tz":-330},"id":"ITdr9sGW9rOV","outputId":"00a39284-6fab-4020-819c-aa1336e7c2b2"},"outputs":[],"source":["discriminator_losses = []\n","for epoch in range(num_epochs):\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    fake_student_data = generator.predict(noise)\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    real_student_data = X_train[idx]\n","    d_loss_real = discriminator.train_on_batch(real_student_data, np.ones((batch_size, 1)))\n","    d_loss_fake = discriminator.train_on_batch(fake_student_data, np.zeros((batch_size, 1)))\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","    discriminator_losses.append(d_loss)\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n","    print(f\"Epoch: {epoch+1}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n","\n","threshold = 0.1"]},{"cell_type":"markdown","metadata":{},"source":["1/1 [==============================] - 0s 78ms/step\n","Epoch: 1, Discriminator Loss: 0.623881921172142, Generator Loss: 0.6012363433837891\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 2, Discriminator Loss: 0.37799350963905454, Generator Loss: 0.7477388381958008\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 3, Discriminator Loss: 0.30502695264294744, Generator Loss: 0.8845016360282898\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 4, Discriminator Loss: 0.2506387762259692, Generator Loss: 1.0242806673049927\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 5, Discriminator Loss: 0.21092747536022216, Generator Loss: 1.175811529159546\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 6, Discriminator Loss: 0.17401077318936586, Generator Loss: 1.3445982933044434\n","1/1 [==============================] - 0s 23ms/step\n","Epoch: 7, Discriminator Loss: 0.14326616236940026, Generator Loss: 1.5263469219207764\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 8, Discriminator Loss: 0.11896649457048625, Generator Loss: 1.7140936851501465\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 9, Discriminator Loss: 0.1002053152769804, Generator Loss: 1.9125033617019653\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 10, Discriminator Loss: 0.07865146896801889, Generator Loss: 2.097902536392212\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 11, Discriminator Loss: 0.06858023791573942, Generator Loss: 2.264525890350342\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 12, Discriminator Loss: 0.059400064405053854, Generator Loss: 2.460902452468872\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 13, Discriminator Loss: 0.052326171193271875, Generator Loss: 2.5929198265075684\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 14, Discriminator Loss: 0.0480084412265569, Generator Loss: 2.6160435676574707\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 15, Discriminator Loss: 0.04277648194693029, Generator Loss: 2.716498613357544\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 16, Discriminator Loss: 0.04477113636676222, Generator Loss: 2.8231496810913086\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 17, Discriminator Loss: 0.04812898358795792, Generator Loss: 2.7353367805480957\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 18, Discriminator Loss: 0.048902221489697695, Generator Loss: 2.6726746559143066\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 19, Discriminator Loss: 0.05273164715617895, Generator Loss: 2.573610782623291\n","1/1 [==============================] - 0s 21ms/step\n","Epoch: 20, Discriminator Loss: 0.05618555401451886, Generator Loss: 2.548572540283203\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 21, Discriminator Loss: 0.06638636766001582, Generator Loss: 2.308764696121216\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 22, Discriminator Loss: 0.07778745144605637, Generator Loss: 2.305426597595215\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 23, Discriminator Loss: 0.08074514009058475, Generator Loss: 2.150315999984741\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 24, Discriminator Loss: 0.08781463885679841, Generator Loss: 2.0781378746032715\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 25, Discriminator Loss: 0.08119455527048558, Generator Loss: 2.1698315143585205\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 26, Discriminator Loss: 0.07811469794251025, Generator Loss: 2.205110549926758\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 27, Discriminator Loss: 0.0714961844496429, Generator Loss: 2.232905149459839\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 28, Discriminator Loss: 0.07327522244304419, Generator Loss: 2.2079858779907227\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 29, Discriminator Loss: 0.07841819641180336, Generator Loss: 2.117684841156006\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 30, Discriminator Loss: 0.09519316325895488, Generator Loss: 1.9037699699401855\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 31, Discriminator Loss: 0.10685841155645903, Generator Loss: 1.9119536876678467\n","1/1 [==============================] - 0s 23ms/step\n","Epoch: 32, Discriminator Loss: 0.1676519401371479, Generator Loss: 1.5567981004714966\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 33, Discriminator Loss: 0.14461377894986072, Generator Loss: 1.5028477907180786\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 34, Discriminator Loss: 0.14328525392693336, Generator Loss: 1.5727874040603638\n","1/1 [==============================] - 0s 19ms/step\n","Epoch: 35, Discriminator Loss: 0.12006446369491641, Generator Loss: 1.8247655630111694\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 36, Discriminator Loss: 0.09065800912048871, Generator Loss: 2.100806713104248\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 37, Discriminator Loss: 0.058778542443178594, Generator Loss: 2.451446294784546\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 38, Discriminator Loss: 0.14741291105747223, Generator Loss: 2.2268967628479004\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 39, Discriminator Loss: 0.0646307051390167, Generator Loss: 2.0562539100646973\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 40, Discriminator Loss: 0.07536807667592463, Generator Loss: 2.0066170692443848\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 41, Discriminator Loss: 0.07644799351775818, Generator Loss: 2.0706005096435547\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 42, Discriminator Loss: 0.06758494675159593, Generator Loss: 2.209115505218506\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 43, Discriminator Loss: 0.0593094453215601, Generator Loss: 2.3162426948547363\n","1/1 [==============================] - 0s 23ms/step\n","Epoch: 44, Discriminator Loss: 0.06289426982403142, Generator Loss: 2.3510942459106445\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 45, Discriminator Loss: 0.08316199481487413, Generator Loss: 2.0380606651306152\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 46, Discriminator Loss: 0.11929800361397531, Generator Loss: 1.8437061309814453\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 47, Discriminator Loss: 0.09969729185105547, Generator Loss: 1.9891248941421509\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 48, Discriminator Loss: 0.06749355793388179, Generator Loss: 2.345831871032715\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 49, Discriminator Loss: 0.0441960617958044, Generator Loss: 2.6477911472320557\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 50, Discriminator Loss: 0.03268334404694939, Generator Loss: 2.9105160236358643\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 51, Discriminator Loss: 0.02492551893493765, Generator Loss: 3.1507606506347656\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 52, Discriminator Loss: 0.019623678457431737, Generator Loss: 3.3737239837646484\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 53, Discriminator Loss: 0.01585414593864698, Generator Loss: 3.5737528800964355\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 54, Discriminator Loss: 0.013412490574410185, Generator Loss: 3.755411148071289\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 55, Discriminator Loss: 0.13995973765850067, Generator Loss: 3.730556011199951\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 56, Discriminator Loss: 0.02153980638831854, Generator Loss: 3.6669247150421143\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 57, Discriminator Loss: 0.013257704578328422, Generator Loss: 3.6296920776367188\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 58, Discriminator Loss: 0.0136376563706107, Generator Loss: 3.6145472526550293\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 59, Discriminator Loss: 0.01369759067893916, Generator Loss: 3.618767023086548\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 60, Discriminator Loss: 0.013555457815562546, Generator Loss: 3.63270902633667\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 61, Discriminator Loss: 0.01333882659673733, Generator Loss: 3.6541314125061035\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 62, Discriminator Loss: 0.0130143715068701, Generator Loss: 3.680548906326294\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 63, Discriminator Loss: 0.012732304632663817, Generator Loss: 3.7056665420532227\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 64, Discriminator Loss: 0.0130601562559605, Generator Loss: 3.703077554702759\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 65, Discriminator Loss: 0.01594755426049235, Generator Loss: 3.511786699295044\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 66, Discriminator Loss: 0.024549599736928964, Generator Loss: 3.22346568107605\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 67, Discriminator Loss: 0.030175644904375114, Generator Loss: 3.0266990661621094\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 68, Discriminator Loss: 0.024295218288898714, Generator Loss: 3.266944408416748\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 69, Discriminator Loss: 0.016964236274361652, Generator Loss: 3.569794178009033\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 70, Discriminator Loss: 0.012433241121470944, Generator Loss: 3.858548641204834\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 71, Discriminator Loss: 0.009311687201267163, Generator Loss: 4.132821083068848\n","1/1 [==============================] - 0s 19ms/step\n","Epoch: 72, Discriminator Loss: 0.007128487341106322, Generator Loss: 4.383180141448975\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 73, Discriminator Loss: 0.00559849292040741, Generator Loss: 4.61116886138916\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 74, Discriminator Loss: 0.00451084552408843, Generator Loss: 4.807563781738281\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 75, Discriminator Loss: 0.00376323121599907, Generator Loss: 4.9800591468811035\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 76, Discriminator Loss: 0.0031905272047244057, Generator Loss: 5.136855125427246\n","1/1 [==============================] - 0s 19ms/step\n","Epoch: 77, Discriminator Loss: 0.002742231823504708, Generator Loss: 5.282025337219238\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 78, Discriminator Loss: 0.0023816630710260236, Generator Loss: 5.418517112731934\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 79, Discriminator Loss: 0.0020844512621260875, Generator Loss: 5.547975540161133\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 80, Discriminator Loss: 0.0018375897830647902, Generator Loss: 5.671137809753418\n","1/1 [==============================] - 0s 20ms/step\n","Epoch: 81, Discriminator Loss: 0.0016278687551581975, Generator Loss: 5.787439346313477\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 82, Discriminator Loss: 0.0014550281753766825, Generator Loss: 5.896020889282227\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 83, Discriminator Loss: 0.0013100234823788526, Generator Loss: 6.000351905822754\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 84, Discriminator Loss: 0.0011796036537910226, Generator Loss: 6.104654312133789\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 85, Discriminator Loss: 0.0010629953726156438, Generator Loss: 6.2073259353637695\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 86, Discriminator Loss: 0.0009620605898003039, Generator Loss: 6.305461883544922\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 87, Discriminator Loss: 0.0008726277232057097, Generator Loss: 6.399545669555664\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 88, Discriminator Loss: 0.0007956487966556125, Generator Loss: 6.491371154785156\n","1/1 [==============================] - 0s 20ms/step\n","Epoch: 89, Discriminator Loss: 0.0007258744029599029, Generator Loss: 6.584486484527588\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 90, Discriminator Loss: 0.0006601120645917113, Generator Loss: 6.678915023803711\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 91, Discriminator Loss: 0.000603695473046173, Generator Loss: 6.770786762237549\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 92, Discriminator Loss: 0.0005510742810215432, Generator Loss: 6.863181114196777\n","1/1 [==============================] - 0s 21ms/step\n","Epoch: 93, Discriminator Loss: 0.0005070986317150528, Generator Loss: 6.954822063446045\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 94, Discriminator Loss: 0.0004591155312994033, Generator Loss: 7.041896820068359\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 95, Discriminator Loss: 0.00043754004673246527, Generator Loss: 7.102133274078369\n","1/1 [==============================] - 0s 18ms/step\n","Epoch: 96, Discriminator Loss: 0.0003993098499917025, Generator Loss: 7.195601463317871\n","1/1 [==============================] - 0s 17ms/step\n","Epoch: 97, Discriminator Loss: 0.00039430787924743527, Generator Loss: 7.181300163269043\n","1/1 [==============================] - 0s 16ms/step\n","Epoch: 98, Discriminator Loss: 0.000413235192670669, Generator Loss: 7.1613874435424805\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 99, Discriminator Loss: 0.0007721026631770656, Generator Loss: 6.794639587402344\n","1/1 [==============================] - 0s 15ms/step\n","Epoch: 100, Discriminator Loss: 0.0012151042759623032, Generator Loss: 6.107326507568359"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake_students = []\n","real_students = []\n","\n","for epoch, discriminator_loss in enumerate(discriminator_losses, 1):\n","    if discriminator_loss < threshold:\n","        fake_students.append((epoch, discriminator_loss))\n","    else:\n","        real_students.append((epoch, discriminator_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Fake Students:\")\n","for student in fake_students:\n","    print(\"Epoch:\", student[0], \"Discriminator Loss:\", student[1])"]},{"cell_type":"markdown","metadata":{},"source":["Fake Students:\n","Epoch: 10 Discriminator Loss: 0.07865146896801889\n","Epoch: 11 Discriminator Loss: 0.06858023791573942\n","Epoch: 12 Discriminator Loss: 0.059400064405053854\n","Epoch: 13 Discriminator Loss: 0.052326171193271875\n","Epoch: 14 Discriminator Loss: 0.0480084412265569\n","Epoch: 15 Discriminator Loss: 0.04277648194693029\n","Epoch: 16 Discriminator Loss: 0.04477113636676222\n","Epoch: 17 Discriminator Loss: 0.04812898358795792\n","Epoch: 18 Discriminator Loss: 0.048902221489697695\n","Epoch: 19 Discriminator Loss: 0.05273164715617895\n","Epoch: 20 Discriminator Loss: 0.05618555401451886\n","Epoch: 21 Discriminator Loss: 0.06638636766001582\n","Epoch: 22 Discriminator Loss: 0.07778745144605637\n","Epoch: 23 Discriminator Loss: 0.08074514009058475\n","Epoch: 24 Discriminator Loss: 0.08781463885679841\n","Epoch: 25 Discriminator Loss: 0.08119455527048558\n","Epoch: 26 Discriminator Loss: 0.07811469794251025\n","Epoch: 27 Discriminator Loss: 0.0714961844496429\n","Epoch: 28 Discriminator Loss: 0.07327522244304419\n","Epoch: 29 Discriminator Loss: 0.07841819641180336\n","Epoch: 30 Discriminator Loss: 0.09519316325895488\n","Epoch: 36 Discriminator Loss: 0.09065800912048871\n","Epoch: 37 Discriminator Loss: 0.058778542443178594\n","Epoch: 39 Discriminator Loss: 0.0646307051390167\n","Epoch: 40 Discriminator Loss: 0.07536807667592463\n","Epoch: 41 Discriminator Loss: 0.07644799351775818\n","Epoch: 42 Discriminator Loss: 0.06758494675159593\n","Epoch: 43 Discriminator Loss: 0.0593094453215601\n","Epoch: 44 Discriminator Loss: 0.06289426982403142\n","Epoch: 45 Discriminator Loss: 0.08316199481487413\n","Epoch: 47 Discriminator Loss: 0.09969729185105547\n","Epoch: 48 Discriminator Loss: 0.06749355793388179\n","Epoch: 49 Discriminator Loss: 0.0441960617958044\n","Epoch: 50 Discriminator Loss: 0.03268334404694939\n","Epoch: 51 Discriminator Loss: 0.02492551893493765\n","Epoch: 52 Discriminator Loss: 0.019623678457431737\n","Epoch: 53 Discriminator Loss: 0.01585414593864698\n","Epoch: 54 Discriminator Loss: 0.013412490574410185\n","Epoch: 56 Discriminator Loss: 0.02153980638831854\n","Epoch: 57 Discriminator Loss: 0.013257704578328422\n","Epoch: 58 Discriminator Loss: 0.0136376563706107\n","Epoch: 59 Discriminator Loss: 0.01369759067893916\n","Epoch: 60 Discriminator Loss: 0.013555457815562546\n","Epoch: 61 Discriminator Loss: 0.01333882659673733\n","Epoch: 62 Discriminator Loss: 0.0130143715068701\n","Epoch: 63 Discriminator Loss: 0.012732304632663817\n","Epoch: 64 Discriminator Loss: 0.0130601562559605\n","Epoch: 65 Discriminator Loss: 0.01594755426049235\n","Epoch: 66 Discriminator Loss: 0.024549599736928964\n","Epoch: 67 Discriminator Loss: 0.030175644904375114\n","Epoch: 68 Discriminator Loss: 0.024295218288898714\n","Epoch: 69 Discriminator Loss: 0.016964236274361652\n","Epoch: 70 Discriminator Loss: 0.012433241121470944\n","Epoch: 71 Discriminator Loss: 0.009311687201267163\n","Epoch: 72 Discriminator Loss: 0.007128487341106322\n","Epoch: 73 Discriminator Loss: 0.00559849292040741\n","Epoch: 74 Discriminator Loss: 0.00451084552408843\n","Epoch: 75 Discriminator Loss: 0.00376323121599907\n","Epoch: 76 Discriminator Loss: 0.0031905272047244057\n","Epoch: 77 Discriminator Loss: 0.002742231823504708\n","Epoch: 78 Discriminator Loss: 0.0023816630710260236\n","Epoch: 79 Discriminator Loss: 0.0020844512621260875\n","Epoch: 80 Discriminator Loss: 0.0018375897830647902\n","Epoch: 81 Discriminator Loss: 0.0016278687551581975\n","Epoch: 82 Discriminator Loss: 0.0014550281753766825\n","Epoch: 83 Discriminator Loss: 0.0013100234823788526\n","Epoch: 84 Discriminator Loss: 0.0011796036537910226\n","Epoch: 85 Discriminator Loss: 0.0010629953726156438\n","Epoch: 86 Discriminator Loss: 0.0009620605898003039\n","Epoch: 87 Discriminator Loss: 0.0008726277232057097\n","Epoch: 88 Discriminator Loss: 0.0007956487966556125\n","Epoch: 89 Discriminator Loss: 0.0007258744029599029\n","Epoch: 90 Discriminator Loss: 0.0006601120645917113\n","Epoch: 91 Discriminator Loss: 0.000603695473046173\n","Epoch: 92 Discriminator Loss: 0.0005510742810215432\n","Epoch: 93 Discriminator Loss: 0.0005070986317150528\n","Epoch: 94 Discriminator Loss: 0.0004591155312994033\n","Epoch: 95 Discriminator Loss: 0.00043754004673246527\n","Epoch: 96 Discriminator Loss: 0.0003993098499917025\n","Epoch: 97 Discriminator Loss: 0.00039430787924743527\n","Epoch: 98 Discriminator Loss: 0.000413235192670669\n","Epoch: 99 Discriminator Loss: 0.0007721026631770656\n","Epoch: 100 Discriminator Loss: 0.0012151042759623032"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nReal Students:\")\n","for student in real_students:\n","    print(\"Epoch:\", student[0], \"Discriminator Loss:\", student[1])"]},{"cell_type":"markdown","metadata":{},"source":["Real Students:\n","Epoch: 1 Discriminator Loss: 0.623881921172142\n","Epoch: 2 Discriminator Loss: 0.37799350963905454\n","Epoch: 3 Discriminator Loss: 0.30502695264294744\n","Epoch: 4 Discriminator Loss: 0.2506387762259692\n","Epoch: 5 Discriminator Loss: 0.21092747536022216\n","Epoch: 6 Discriminator Loss: 0.17401077318936586\n","Epoch: 7 Discriminator Loss: 0.14326616236940026\n","Epoch: 8 Discriminator Loss: 0.11896649457048625\n","Epoch: 9 Discriminator Loss: 0.1002053152769804\n","Epoch: 31 Discriminator Loss: 0.10685841155645903\n","Epoch: 32 Discriminator Loss: 0.1676519401371479\n","Epoch: 33 Discriminator Loss: 0.14461377894986072\n","Epoch: 34 Discriminator Loss: 0.14328525392693336\n","Epoch: 35 Discriminator Loss: 0.12006446369491641\n","Epoch: 38 Discriminator Loss: 0.14741291105747223\n","Epoch: 46 Discriminator Loss: 0.11929800361397531\n","Epoch: 55 Discriminator Loss: 0.13995973765850067"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPuJ4CK18AERwP1I9kWfiAU","gpuType":"T4","mount_file_id":"129v2e_s_XoyMsBD3wM3WJhD_nDt8H4VW","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
